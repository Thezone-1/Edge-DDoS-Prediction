{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "class DDoSDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "class DDoSTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim, num_heads=4, num_layers=2, dim_feedforward=128, dropout=0.1\n",
    "    ):\n",
    "        super(DDoSTransformer, self).__init__()\n",
    "\n",
    "        self.input_projection = nn.Linear(input_dim, dim_feedforward)\n",
    "\n",
    "        self.pos_encoder = nn.Sequential(\n",
    "            nn.Linear(dim_feedforward, dim_feedforward), nn.ReLU(), nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim_feedforward,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=dim_feedforward * 2,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer, num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(dim_feedforward, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_projection(x)\n",
    "\n",
    "        x = self.pos_encoder(x)\n",
    "\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        x = x.mean(dim=1) if len(x.shape) > 2 else x\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def discover_datasets(data_dir=\"datasets\", patterns=None):\n",
    "    \"\"\"\n",
    "    Automatically discover datasets in the specified directory\n",
    "\n",
    "    Args:\n",
    "        data_dir: Directory to search for datasets\n",
    "        patterns: List of file patterns to match (e.g., [\"*.csv\", \"*.parquet\"])\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with dataset names as keys and file paths as values\n",
    "    \"\"\"\n",
    "    if patterns is None:\n",
    "        patterns = [\"*.csv\", \"*.parquet\", \"*.pkl\", \"*.pickle\"]\n",
    "\n",
    "    dataset_paths = {}\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Dataset directory '{data_dir}' not found. Creating it.\")\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        return dataset_paths\n",
    "\n",
    "    for pattern in patterns:\n",
    "        search_pattern = os.path.join(data_dir, pattern)\n",
    "        for file_path in glob.glob(search_pattern):\n",
    "            dataset_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            dataset_paths[dataset_name] = file_path\n",
    "\n",
    "    if not dataset_paths:\n",
    "        print(f\"No datasets found in '{data_dir}' matching patterns: {patterns}\")\n",
    "    else:\n",
    "        print(f\"Discovered {len(dataset_paths)} datasets: {list(dataset_paths.keys())}\")\n",
    "\n",
    "    return dataset_paths\n",
    "\n",
    "\n",
    "def load_datasets(dataset_paths, label_column=\"Label\", feature_columns=None):\n",
    "    \"\"\"\n",
    "    Load multiple datasets from the provided paths\n",
    "\n",
    "    Args:\n",
    "        dataset_paths: Dictionary with dataset names as keys and file paths as values\n",
    "        label_column: Name of the label column in the datasets\n",
    "        feature_columns: Specific feature columns to use (None for all)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with dataset names as keys and (features, labels) tuples as values\n",
    "    \"\"\"\n",
    "    datasets = {}\n",
    "\n",
    "    for dataset_name, file_path in dataset_paths.items():\n",
    "        print(f\"Loading dataset: {dataset_name} from {file_path}\")\n",
    "\n",
    "        try:\n",
    "            if file_path.endswith('.csv'):\n",
    "                data = pd.read_csv(file_path)\n",
    "            elif file_path.endswith('.parquet'):\n",
    "                data = pd.read_parquet(file_path)\n",
    "            elif file_path.endswith('.pkl') or file_path.endswith('.pickle'):\n",
    "                data = pd.read_pickle(file_path)\n",
    "            else:\n",
    "                print(f\"Unsupported file format for {file_path}. Skipping.\")\n",
    "                continue\n",
    "            if label_column in data.columns:\n",
    "                if feature_columns is not None:\n",
    "                    missing_cols = [col for col in feature_columns if col not in data.columns]\n",
    "                    if missing_cols:\n",
    "                        print(f\"Warning: Columns {missing_cols} not found in {dataset_name}\")\n",
    "                    available_cols = [col for col in feature_columns if col in data.columns]\n",
    "                    X = data[available_cols].values\n",
    "                else:\n",
    "                    X = data.drop(label_column, axis=1).values\n",
    "\n",
    "                y = data[label_column].values\n",
    "\n",
    "                if not np.all(np.isin(np.unique(y), [0, 1])):\n",
    "                    print(f\"Converting labels for {dataset_name} to binary format\")\n",
    "                    unique_labels = np.unique(y)\n",
    "                    label_map = {unique_labels[i]: i for i in range(len(unique_labels))}\n",
    "                    y = np.array([label_map[label] for label in y])\n",
    "\n",
    "                datasets[dataset_name] = (X, y)\n",
    "                print(f\"Successfully loaded {dataset_name}: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "            else:\n",
    "                print(f\"Label column '{label_column}' not found in {dataset_name}. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {dataset_name}: {str(e)}\")\n",
    "\n",
    "    return datasets\n",
    "\n",
    "\n",
    "# Feature alignment for cross-dataset compatibility\n",
    "def align_features(datasets, feature_dim=None, strategy=\"pad_truncate\"):\n",
    "    \"\"\"\n",
    "    Align features across different datasets to make them compatible\n",
    "\n",
    "    Args:\n",
    "        datasets: Dictionary with dataset names as keys and (features, labels) tuples as values\n",
    "        feature_dim: Target feature dimension (None to use the max dimension)\n",
    "        strategy: Strategy to use for alignment (\"pad_truncate\" or \"pca\")\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with aligned datasets and a common feature dimension\n",
    "    \"\"\"\n",
    "    if not datasets:\n",
    "        return {}, 0\n",
    "\n",
    "    dimensions = {name: X.shape[1] for name, (X, _) in datasets.items()}\n",
    "\n",
    "    if feature_dim is None:\n",
    "        feature_dim = max(dimensions.values())\n",
    "\n",
    "    print(f\"Aligning all datasets to {feature_dim} features using strategy: {strategy}\")\n",
    "\n",
    "    aligned_datasets = {}\n",
    "\n",
    "    for name, (X, y) in datasets.items():\n",
    "        current_dim = X.shape[1]\n",
    "\n",
    "        if current_dim == feature_dim:\n",
    "            aligned_datasets[name] = (X, y)\n",
    "        elif current_dim < feature_dim:\n",
    "            if strategy == \"pad_truncate\":\n",
    "                padding = np.zeros((X.shape[0], feature_dim - current_dim))\n",
    "                X_aligned = np.hstack((X, padding))\n",
    "                print(f\"Padded {name} from {current_dim} to {feature_dim} features\")\n",
    "                aligned_datasets[name] = (X_aligned, y)\n",
    "            else:\n",
    "                print(f\"Cannot use PCA to increase dimensions. Padding {name} instead.\")\n",
    "                padding = np.zeros((X.shape[0], feature_dim - current_dim))\n",
    "                X_aligned = np.hstack((X, padding))\n",
    "                aligned_datasets[name] = (X_aligned, y)\n",
    "        else:\n",
    "            if strategy == \"pad_truncate\":\n",
    "                X_aligned = X[:, :feature_dim]\n",
    "                print(f\"Truncated {name} from {current_dim} to {feature_dim} features\")\n",
    "                aligned_datasets[name] = (X_aligned, y)\n",
    "            else:\n",
    "                from sklearn.decomposition import PCA\n",
    "                pca = PCA(n_components=feature_dim)\n",
    "                X_aligned = pca.fit_transform(X)\n",
    "                print(f\"Reduced {name} from {current_dim} to {feature_dim} features using PCA\")\n",
    "                aligned_datasets[name] = (X_aligned, y)\n",
    "\n",
    "    return aligned_datasets, feature_dim\n",
    "\n",
    "\n",
    "def create_train_test_combinations(datasets, test_size=0.2, random_state=42, cross_dataset=True):\n",
    "    \"\"\"\n",
    "    Create various train/test combinations from the available datasets\n",
    "\n",
    "    Args:\n",
    "        datasets: Dictionary with dataset names as keys and (features, labels) tuples as values\n",
    "        test_size: Proportion to use for testing when splitting individual datasets\n",
    "        random_state: Random seed for reproducibility\n",
    "        cross_dataset: Whether to create cross-dataset combinations\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries with train/test dataset configurations\n",
    "    \"\"\"\n",
    "    combinations = []\n",
    "\n",
    "    for dataset_name, (X, y) in datasets.items():\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "\n",
    "        combinations.append({\n",
    "            'name': f\"{dataset_name}_internal_split\",\n",
    "            'train': {\n",
    "                'X': X_train,\n",
    "                'y': y_train,\n",
    "                'dataset': dataset_name,\n",
    "                'split': 'train'\n",
    "            },\n",
    "            'test': {\n",
    "                'X': X_test,\n",
    "                'y': y_test,\n",
    "                'dataset': dataset_name,\n",
    "                'split': 'test'\n",
    "            }\n",
    "        })\n",
    "    if cross_dataset and len(datasets) > 1:\n",
    "        dataset_names = list(datasets.keys())\n",
    "\n",
    "        for train_name, test_name in itertools.permutations(dataset_names, 2):\n",
    "            X_train, y_train = datasets[train_name]\n",
    "            X_test, y_test = datasets[test_name]\n",
    "\n",
    "            combinations.append({\n",
    "                'name': f\"train_{train_name}_test_{test_name}\",\n",
    "                'train': {\n",
    "                    'X': X_train,\n",
    "                    'y': y_train,\n",
    "                    'dataset': train_name,\n",
    "                    'split': 'full'\n",
    "                },\n",
    "                'test': {\n",
    "                    'X': X_test,\n",
    "                    'y': y_test,\n",
    "                    'dataset': test_name,\n",
    "                    'split': 'full'\n",
    "                }\n",
    "            })\n",
    "\n",
    "    return combinations\n",
    "\n",
    "def prepare_dataset_combination(combination, batch_size=32):\n",
    "    \"\"\"\n",
    "    Prepare a specific train/test combination for model training and evaluation\n",
    "\n",
    "    Args:\n",
    "        combination: Dictionary with train/test dataset configuration\n",
    "        batch_size: Batch size for DataLoader\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with prepared data loaders and related information\n",
    "    \"\"\"\n",
    "    X_train = combination['train']['X']\n",
    "    y_train = combination['train']['y']\n",
    "    X_test = combination['test']['X']\n",
    "    y_test = combination['test']['y']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    train_dataset = DDoSDataset(X_train_scaled, y_train)\n",
    "    test_dataset = DDoSDataset(X_test_scaled, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    prepared_data = {\n",
    "        'name': combination['name'],\n",
    "        'train_loader': train_loader,\n",
    "        'test_loader': test_loader,\n",
    "        'scaler': scaler,\n",
    "        'input_dim': X_train.shape[1],\n",
    "        'train_info': combination['train'],\n",
    "        'test_info': combination['test'],\n",
    "        'X_test': X_test_scaled,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "    return prepared_data\n",
    "\n",
    "def train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, num_epochs=10, device=\"cuda\",\n",
    "    experiment_name=\"unnamed\", early_stopping_patience=5, model_dir=\"models\"\n",
    "):\n",
    "    model = model.to(device)\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    best_model_path = os.path.join(model_dir, f\"best_model_{experiment_name}_{timestamp}.pth\")\n",
    "\n",
    "    patience_counter = 0\n",
    "    early_stop = False\n",
    "\n",
    "    training_history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if early_stop:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs\")\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(\n",
    "                device\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += batch_labels.size(0)\n",
    "            correct += predicted.eq(batch_labels).sum().item()\n",
    "\n",
    "        epoch_train_loss = train_loss/len(train_loader)\n",
    "        train_accuracy = 100.*correct/total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_labels in val_loader:\n",
    "                batch_features, batch_labels = batch_features.to(\n",
    "                    device\n",
    "                ), batch_labels.to(device)\n",
    "                outputs = model(batch_features)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += batch_labels.size(0)\n",
    "                val_correct += predicted.eq(batch_labels).sum().item()\n",
    "\n",
    "        epoch_val_loss = val_loss/len(val_loader)\n",
    "        val_accuracy = 100.*val_correct/val_total\n",
    "\n",
    "        training_history['train_loss'].append(epoch_train_loss)\n",
    "        training_history['train_acc'].append(train_accuracy)\n",
    "        training_history['val_loss'].append(epoch_val_loss)\n",
    "        training_history['val_acc'].append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} for {experiment_name}:\")\n",
    "        print(\n",
    "            f\"Train Loss: {epoch_train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Val Loss: {epoch_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\"\n",
    "        )\n",
    "\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                early_stop = True\n",
    "                print(f\"No improvement for {early_stopping_patience} epochs. Early stopping.\")\n",
    "\n",
    "    print(f\"Training complete for {experiment_name}. Best model saved to '{best_model_path}'.\")\n",
    "\n",
    "    history_path = os.path.join(model_dir, f\"training_history_{experiment_name}_{timestamp}.json\")\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(training_history, f)\n",
    "\n",
    "    return best_model_path\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_labels in test_loader:\n",
    "            batch_features = batch_features.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    precision = precision_score(all_targets, all_predictions, zero_division=0)\n",
    "    recall = recall_score(all_targets, all_predictions, zero_division=0)\n",
    "    f1 = f1_score(all_targets, all_predictions, zero_division=0)\n",
    "    conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "    results = {\n",
    "        'test_loss': test_loss / len(test_loader),\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': conf_matrix.tolist()\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_experiments(data_dir=\"datasets\", num_epochs=100, device_str=None,\n",
    "                   model_dir=\"models\", results_dir=\"results\", cross_dataset=True,\n",
    "                   feature_alignment=\"pad_truncate\", batch_size=32):\n",
    "    if device_str is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    else:\n",
    "        device = torch.device(device_str)\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    dataset_paths = discover_datasets(data_dir)\n",
    "    if not dataset_paths:\n",
    "        print(\"No datasets were discovered. Creating demo datasets for testing.\")\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        dataset_paths = create_demo_datasets(num_datasets=3, samples_per_dataset=1000, output_dir=data_dir)\n",
    "\n",
    " \n",
    "    datasets = load_datasets(dataset_paths)\n",
    "    if not datasets:\n",
    "        print(\"No datasets were successfully loaded. Exiting.\")\n",
    "        return\n",
    "\n",
    "    aligned_datasets, common_feature_dim = align_features(datasets, strategy=feature_alignment)\n",
    "\n",
    " \n",
    "    combinations = create_train_test_combinations(aligned_datasets, cross_dataset=cross_dataset)\n",
    "    print(f\"Created {len(combinations)} train/test combinations\")\n",
    "\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    for combination in combinations:\n",
    "        experiment_name = combination['name']\n",
    "        print(f\"\\n=== Running experiment: {experiment_name} ===\")\n",
    "        print(f\"Training on: {combination['train']['dataset']} ({combination['train']['split']})\")\n",
    "        print(f\"Testing on: {combination['test']['dataset']} ({combination['test']['split']})\")\n",
    "\n",
    "        prepared_data = prepare_dataset_combination(combination, batch_size=batch_size)\n",
    "\n",
    "        input_dim = prepared_data['input_dim']\n",
    "        model = DDoSTransformer(input_dim=input_dim)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "      \n",
    "        best_model_path = train_model(\n",
    "            model,\n",
    "            prepared_data['train_loader'],\n",
    "            prepared_data['test_loader'],  \n",
    "            criterion,\n",
    "            optimizer,\n",
    "            num_epochs=num_epochs,\n",
    "            device=device,\n",
    "            experiment_name=experiment_name,\n",
    "            model_dir=model_dir\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        # Evaluate model\n",
    "        evaluation_results = evaluate_model(model, prepared_data['test_loader'], criterion, device=device)\n",
    "\n",
    "        print(f\"\\nResults for {experiment_name}:\")\n",
    "        print(f\"Accuracy: {evaluation_results['accuracy'] * 100:.2f}%\")\n",
    "        print(f\"Precision: {evaluation_results['precision'] * 100:.2f}%\")\n",
    "        print(f\"Recall: {evaluation_results['recall'] * 100:.2f}%\")\n",
    "        print(f\"F1 Score: {evaluation_results['f1_score'] * 100:.2f}%\")\n",
    "\n",
    "        # Store results\n",
    "        all_results[experiment_name] = {\n",
    "            'evaluation': evaluation_results,\n",
    "            'best_model_path': best_model_path,\n",
    "            'train_dataset': combination['train']['dataset'],\n",
    "            'train_split': combination['train']['split'],\n",
    "            'test_dataset': combination['test']['dataset'],\n",
    "            'test_split': combination['test']['split'],\n",
    "            'input_dim': input_dim\n",
    "        }\n",
    "\n",
    "    # Save all results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_path = os.path.join(results_dir, f\"experiment_results_{timestamp}.json\")\n",
    "\n",
    "    # Convert numpy values to native Python types for JSON serialization\n",
    "    serializable_results = {}\n",
    "    for experiment_name, results in all_results.items():\n",
    "        serializable_results[experiment_name] = {\n",
    "            'evaluation': {\n",
    "                'test_loss': float(results['evaluation']['test_loss']),\n",
    "                'accuracy': float(results['evaluation']['accuracy']),\n",
    "                'precision': float(results['evaluation']['precision']),\n",
    "                'recall': float(results['evaluation']['recall']),\n",
    "                'f1_score': float(results['evaluation']['f1_score']),\n",
    "                'confusion_matrix': results['evaluation']['confusion_matrix']\n",
    "            },\n",
    "            'best_model_path': results['best_model_path'],\n",
    "            'train_dataset': results['train_dataset'],\n",
    "            'train_split': results['train_split'],\n",
    "            'test_dataset': results['test_dataset'],\n",
    "            'test_split': results['test_split'],\n",
    "            'input_dim': int(results['input_dim'])\n",
    "        }\n",
    "\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(serializable_results, f, indent=4)\n",
    "\n",
    "    print(f\"\\nAll experiment results saved to {results_path}\")\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# Function to create a demonstration with dummy data if no real datasets are available\n",
    "def create_demo_datasets(num_datasets=3, samples_per_dataset=1000, output_dir=\"datasets\"):\n",
    "    \"\"\"Create demo datasets for testing purposes\"\"\"\n",
    "    dataset_paths = {}\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for i in range(1, num_datasets + 1):\n",
    "        # Create random feature dimensions to simulate different datasets\n",
    "        feature_dim = np.random.randint(20, 50)\n",
    "\n",
    "        # Generate random data\n",
    "        X = np.random.randn(samples_per_dataset, feature_dim)\n",
    "\n",
    "        # Generate labels with some class imbalance\n",
    "        imbalance_ratio = np.random.uniform(0.1, 0.3)  # 10-30% minority class\n",
    "        num_positive = int(samples_per_dataset * imbalance_ratio)\n",
    "        y = np.zeros(samples_per_dataset)\n",
    "        y[:num_positive] = 1\n",
    "        np.random.shuffle(y)\n",
    "\n",
    "        cols = [f\"feature_{j}\" for j in range(feature_dim)]\n",
    "        df = pd.DataFrame(X, columns=cols)\n",
    "        df['Label'] = y.astype(int)\n",
    "\n",
    "        \n",
    "        filename = f\"{output_dir}/dataset_{i}.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "        dataset_paths[f\"Dataset_{i}\"] = filename\n",
    "\n",
    "    print(f\"Created {num_datasets} demo datasets in {output_dir}\")\n",
    "    return dataset_paths\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    results = run_experiments(\n",
    "        data_dir=\"datasets\",          \n",
    "        num_epochs=50,                 \n",
    "        model_dir=\"models\",            \n",
    "        results_dir=\"results\",         \n",
    "        cross_dataset=True,            \n",
    "        feature_alignment=\"pad_truncate\", \n",
    "        batch_size=32                  \n",
    "    )\n",
    "\n",
    "    print(\"\\nSummary of cross-dataset performance:\")\n",
    "    for experiment_name, experiment_results in results.items():\n",
    "        if experiment_results['train_dataset'] != experiment_results['test_dataset']:\n",
    "            eval_results = experiment_results['evaluation']\n",
    "            print(f\"\\n{experiment_name}:\")\n",
    "            print(f\"  Train: {experiment_results['train_dataset']}\")\n",
    "            print(f\"  Test: {experiment_results['test_dataset']}\")\n",
    "            print(f\"  Accuracy: {eval_results['accuracy'] * 100:.2f}%\")\n",
    "            print(f\"  F1 Score: {eval_results['f1_score'] * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
